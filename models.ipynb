{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session = SparkSession.builder.master(\"local[*]\").config(\"spark.driver.memory\", \"15g\").appName('Models').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets with spark\n",
    "train_df_spark = spark_session.read.csv('train.csv', header=True, inferSchema=True)\n",
    "test_df_spark = spark_session.read.csv('test.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = train_df_spark.columns[:-1]\n",
    "output_col = train_df_spark.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+------+--------------------+\n",
      "| f1| f2| f3| f4| f5| f6| f7| f8| f9|f10|target|            features|\n",
      "+---+---+---+---+---+---+---+---+---+---+------+--------------------+\n",
      "|  0| 21| 20| 61| 51|142|141|  8|  4|  0|     0|[0.0,21.0,20.0,61...|\n",
      "|  0| 14| 15| 29| 35|164|168|  4|  4|  0|     0|[0.0,14.0,15.0,29...|\n",
      "|  1| 20|  8| 65| 59|221|225|  4|  4|  0|     0|[1.0,20.0,8.0,65....|\n",
      "|101| 14| 13| 78| 84|111|120|  4|  4|  0|     1|[101.0,14.0,13.0,...|\n",
      "|  0|  0| 11| 20| 52| 47| 66|  7|  7|  0|     0|[0.0,0.0,11.0,20....|\n",
      "+---+---+---+---+---+---+---+---+---+---+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+---+---+---+---+---+---+---+---+---+------+--------------------+\n",
      "| f1| f2| f3| f4| f5| f6| f7| f8| f9|f10|target|            features|\n",
      "+---+---+---+---+---+---+---+---+---+---+------+--------------------+\n",
      "|  0| 14| 13| 50| 47| 87| 65|  0|  4|  0|     0|[0.0,14.0,13.0,50...|\n",
      "|  0| 14| 21| 65| 67|147|143|  4|  4|  0|     0|[0.0,14.0,21.0,65...|\n",
      "|  0| 34| 22| 34| 17| 49| 25|  0|  0|  0|     0|[0.0,34.0,22.0,34...|\n",
      "|  0| 14| 13| 39| 33| 74| 64|  0|  4|  0|     0|[0.0,14.0,13.0,39...|\n",
      "|  0| 14|  8| 66| 69| 57| 52|  4|  4|  0|     0|[0.0,14.0,8.0,66....|\n",
      "+---+---+---+---+---+---+---+---+---+---+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode the features into a vector\n",
    "featureassemble = VectorAssembler(inputCols=input_cols, outputCol='features')\n",
    "output = featureassemble.transform(train_df_spark)\n",
    "output.show(n=5)\n",
    "\n",
    "testfeatureassemble = VectorAssembler(inputCols=input_cols, outputCol='features')\n",
    "testoutput = testfeatureassemble.transform(test_df_spark)\n",
    "testoutput.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features|target|\n",
      "+--------------------+------+\n",
      "|[0.0,21.0,20.0,61...|     0|\n",
      "|[0.0,14.0,15.0,29...|     0|\n",
      "|[1.0,20.0,8.0,65....|     0|\n",
      "|[101.0,14.0,13.0,...|     1|\n",
      "|[0.0,0.0,11.0,20....|     0|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+------+\n",
      "|            features|target|\n",
      "+--------------------+------+\n",
      "|[0.0,14.0,13.0,50...|     0|\n",
      "|[0.0,14.0,21.0,65...|     0|\n",
      "|[0.0,34.0,22.0,34...|     0|\n",
      "|[0.0,14.0,13.0,39...|     0|\n",
      "|[0.0,14.0,8.0,66....|     0|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the features and the target column\n",
    "\n",
    "train = output.select('features', 'target') \n",
    "train.show(n=5)\n",
    "\n",
    "test = testoutput.select('features', 'target')\n",
    "test.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features|target|\n",
      "+--------------------+------+\n",
      "|[0.0,21.0,20.0,61...|     0|\n",
      "|[0.0,14.0,15.0,29...|     0|\n",
      "|[1.0,20.0,8.0,65....|     0|\n",
      "|[101.0,14.0,13.0,...|     1|\n",
      "|[0.0,0.0,11.0,20....|     0|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+------+\n",
      "|            features|target|\n",
      "+--------------------+------+\n",
      "|[0.0,14.0,13.0,50...|     0|\n",
      "|[0.0,14.0,21.0,65...|     0|\n",
      "|[0.0,34.0,22.0,34...|     0|\n",
      "|[0.0,14.0,13.0,39...|     0|\n",
      "|[0.0,14.0,8.0,66....|     0|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the features and the target column\n",
    "train = output.select('features', output_col)\n",
    "train.show(n=5)\n",
    "\n",
    "test = testoutput.select('features', output_col)\n",
    "test.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.08%\n",
      "Weighted Precision: 82.99%\n",
      "Weighted Recall: 84.08%\n",
      "F1 Score: 82.86%\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(labelCol=output_col).fit(train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "results = classifier.evaluate(test) \n",
    "\n",
    "# Print the accuracy, precision, recall and f1 score\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(results.predictions)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "weightedPrecision = evaluator.evaluate(results.predictions)\n",
    "print(f\"Weighted Precision: {weightedPrecision*100:.2f}%\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "weightedRecall = evaluator.evaluate(results.predictions)\n",
    "print(f\"Weighted Recall: {weightedRecall*100:.2f}%\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluator.evaluate(results.predictions)\n",
    "print(f\"F1 Score: {f1*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.79%\n",
      "Weighted Precision: 79.18%\n",
      "Weighted Recall: 76.79%\n",
      "F1 Score: 77.70%\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayes(labelCol=output_col, featuresCol='features')\n",
    "classifier = classifier.fit(train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "results = classifier.transform(test)\n",
    "\n",
    "# Print the accuracy, precision, recall and f1 score\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(results)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "weightedPrecision = evaluator.evaluate(results)\n",
    "print(f\"Weighted Precision: {weightedPrecision*100:.2f}%\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "weightedRecall = evaluator.evaluate(results)\n",
    "print(f\"Weighted Recall: {weightedRecall*100:.2f}%\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluator.evaluate(results)\n",
    "print(f\"F1 Score: {f1*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.54%\n",
      "Weighted Precision: 82.67%\n",
      "Weighted Recall: 83.54%\n",
      "F1 Score: 81.37%\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(numTrees=100, labelCol=output_col, featuresCol='features')\n",
    "classifier = classifier.fit(train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "results = classifier.transform(test)\n",
    "\n",
    "# Print the accuracy, precision, recall and f1 score\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(results)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "weightedPrecision = evaluator.evaluate(results)\n",
    "print(f\"Weighted Precision: {weightedPrecision*100:.2f}%\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "weightedRecall = evaluator.evaluate(results)\n",
    "print(f\"Weighted Recall: {weightedRecall*100:.2f}%\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluator.evaluate(results)\n",
    "print(f\"F1 Score: {f1*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.93%\n",
      "Weighted Precision: 82.85%\n",
      "Weighted Recall: 83.93%\n",
      "F1 Score: 82.45%\n"
     ]
    }
   ],
   "source": [
    "classifier = LinearSVC(labelCol=output_col, featuresCol='features')\n",
    "classifier = classifier.fit(train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "results = classifier.transform(test)\n",
    "\n",
    "# Print the accuracy, precision, recall and f1 score\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(results)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "weightedPrecision = evaluator.evaluate(results)\n",
    "print(f\"Weighted Precision: {weightedPrecision*100:.2f}%\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "weightedRecall = evaluator.evaluate(results)\n",
    "print(f\"Weighted Recall: {weightedRecall*100:.2f}%\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=output_col, predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluator.evaluate(results)\n",
    "print(f\"F1 Score: {f1*100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier using Map-Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to RDD\n",
    "train_rdd_spark = train_df_spark.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurence of each class and each value of the features\n",
    "f_map = []\n",
    "for i in range(len(input_cols)):\n",
    "    f_map.append(train_rdd_spark.map(lambda x: ((x[i]), 1)))\n",
    "target_map = train_rdd_spark.map(lambda x: (x[len(input_cols)], 1))\n",
    "\n",
    "# Reduce the data to count the number of each class\n",
    "f_reduce = []\n",
    "for i in range(len(input_cols)):\n",
    "    f_reduce.append(f_map[i].reduceByKey(lambda x, y: x + y))\n",
    "target_reduce = target_map.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "\n",
    "# Map the data to count the occurence of each class with the different values of the features\n",
    "f_target_map = []\n",
    "for i in range(len(input_cols)):\n",
    "    f_target_map.append(train_rdd_spark.map(lambda x: ((x[i], x[len(input_cols)]), 1)))\n",
    "\n",
    "# Reduce the data to count the number of each class\n",
    "f_target_reduce = []\n",
    "for i in range(len(input_cols)):\n",
    "    f_target_reduce.append(f_target_map[i].reduceByKey(lambda x, y: x + y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probability of each class for each value of the features\n",
    "prop_f_target_reduce = []\n",
    "for i in range(len(input_cols)):\n",
    "    prop_f_target_reduce.append(f_target_reduce[i].map(lambda x: (x[0][0], (x[0][1], x[1]))))\n",
    "    prop_f_target_reduce[i] = prop_f_target_reduce[i].join(f_reduce[i])\n",
    "    prop_f_target_reduce[i] = prop_f_target_reduce[i].map(lambda x: (x[0], (x[1][0][0], x[1][0][1]), x[1][1]))\n",
    "    prop_f_target_reduce[i] = prop_f_target_reduce[i].map(lambda x: (x[0], (x[1][0], x[1][1] / x[2])))\n",
    "    prop_f_target_reduce[i] = prop_f_target_reduce[i].groupByKey().mapValues(list)\n",
    "\n",
    "\n",
    "# Find number of records\n",
    "N = train_rdd_spark.count()\n",
    "prop_target_reduce = target_reduce.map(lambda x: (x[0], x[1] / N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the RDDs to dictionaries to use them in the prediction function\n",
    "prop_f_target_reduce_dict = []\n",
    "for i in range(len(input_cols)):\n",
    "    prop_f_target_reduce_dict.append(prop_f_target_reduce[i].collectAsMap())\n",
    "prop_target_reduce_dict = prop_target_reduce.collectAsMap()\n",
    "\n",
    "# Sort the values of the dictionaries by the class to use them in the prediction function\n",
    "for i in range(len(input_cols)):\n",
    "    for key in prop_f_target_reduce_dict[i]:\n",
    "        prop_f_target_reduce_dict[i][key].sort(key=lambda x: x[0])\n",
    "    \n",
    "prop_target_reduce_dict = sorted(prop_target_reduce_dict.items(), key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the target given features\n",
    "def predict(features):\n",
    "    f_target = []\n",
    "    for i in range(len(input_cols)):\n",
    "        if features[i]  in prop_f_target_reduce_dict[i]:\n",
    "            f_target.append(prop_f_target_reduce_dict[i][features[i]])\n",
    "            f_target[i] = [x[1] for x in f_target[i]]\n",
    "            if len(f_target[i]) < len(prop_target_reduce_dict):\n",
    "                if f_target[i][0] == 0:\n",
    "                    f_target[i].insert(1, 0)\n",
    "                else:\n",
    "                    f_target[i].insert(0, 0)\n",
    "        else:\n",
    "            f_target.append([0] * len(prop_target_reduce_dict))\n",
    "            \n",
    "    prob = [1] * len(f_target[0])\n",
    "\n",
    "    for j in range(len(f_target[0])):\n",
    "        for i in range(len(input_cols)):\n",
    "            prob[j] *= f_target[i][j]\n",
    "    # Argmax\n",
    "    prediction = prob.index(max(prob))\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier with MapReduce\n",
      "Accuracy: 77.70%\n",
      "Precision: 82.17%\n",
      "Recall: 77.70%\n",
      "F1: 68.11%\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "test_features = []\n",
    "for i in range(len(input_cols)):\n",
    "    test_features.append(test_data[input_cols[i]].tolist())\n",
    "\n",
    "y_true = test_data[output_col].tolist()\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(test_features[0])):\n",
    "    features = []\n",
    "    for j in range(len(input_cols)):\n",
    "        features.append(test_features[j][i])\n",
    "    prediction = predict(features)\n",
    "    y_pred.append(prediction)\n",
    "\n",
    "print(\"Naive Bayes Classifier with MapReduce\")\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred) * 100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred, average='weighted') * 100:.2f}%\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred, average='weighted') * 100:.2f}%\")\n",
    "print(f\"F1: {f1_score(y_true, y_pred, average='weighted') * 100:.2f}%\")\n",
    "# print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
